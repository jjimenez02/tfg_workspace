{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Propósito principal </font>\n",
    "- La idea de este librillo es preparar el entorno para realizar pruebas para cualquier DataSet a ser clasificado por cualquier codificación aplicada a SMTS\n",
    "\n",
    "## <font color=#cd0000> Leyenda </font>\n",
    "- Los apartados titulados con el código de colores HEX: `#cd0000` serán apartados que tendrán todos los librillos, en concreto, aquellos especificados en el apartado `Síntesis de los criterios usados` del trabajo.\n",
    "- Los apartados titulados con el código de colores HEX: `#2451ff` serán apartados de conclusiones propias de este librillo resultado de aplicar un estudio personalizado para cada planteamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Prerrequisitos </font>\n",
    "## <font color=#cd0000> Entorno de ejecución </font>\n",
    "- Cambiamos el directorio raíz del librillo para acceder cómodamente a las funciones de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Constantes y variables predefinidas </font>\n",
    "- TODO -> Añadir SEED a todas las particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEARTBEAT_PATH = \"data/heartbeat\"\n",
    "EPILEPSY_PATH = \"data/epilepsy\"\n",
    "SEGUIMIENTO_OCULAR_PATH = \"data/seguimiento-ocular/Data/Hospital\"\n",
    "SEGUIMIENTO_OCULAR_FOLDERS_ID = range(1, 12+1)\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Carga del Dataset </font>\n",
    "- TODO: Breve descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Change with known data\n",
    "from utils.load_data import import_epilepsy_dataset\n",
    "\n",
    "train, test = import_epilepsy_dataset(EPILEPSY_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Preprocesamiento </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Eliminación de datos inválidos y valores atípicos </font>\n",
    "- TODO: Breve descripción de qué es un dato inválido (-1's en columna, etc.)\n",
    "- Eliminaremos aquellos valores fuera de los percentiles 5 y 95.\n",
    "- TODO: Definiremos cuál será el límite de outliers permitido por serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Remove invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.remove_outliers(headers=test.get_derived_data_columns()['attrs']) -> Estos no los podemos alterar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Remaining series\n",
    "print(\"Previous number of series: {}\".format(\n",
    "    len(pd.unique(train.original_data['id']))))\n",
    "print(\"Actual number of series: {}\".format(\n",
    "    len(pd.unique(train.derived_data['id']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Resoluciones a aplicar </font>\n",
    "- TODO:\n",
    "  - Si las series son rápidas (muchos cambios en poco tiempo) especificar resoluciones altas (sin modificaciones).\n",
    "  - Si las series son lentas (pocos cambios en mucho tiempo) especificar resoluciones bajas (eliminamos datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series lentas\n",
    "train.reduce_sampling_rate(remove_one_each_n_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.derived_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Codificación </font>\n",
    "- TODO: Breve descripción de la codificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> División en ventanas </font>\n",
    "- Solo aplicaremos enventanado si no ha sido aplicado anteriormente\n",
    "- TODO: Especificar tamaño de ventana esperado como mejor y adjuntar otro tamaño de ventana para comparar (al menos 2 más)\n",
    "- TODO: No es necesario aplicar siempre el enventanado, revisar análisis en profundidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudiamos eventos globales (series lentas)\n",
    "ws_x = train.get_shortest_serie().shape[0]\n",
    "train_ws_x, train_windows_per_serie_x = \\\n",
    "    train.split_into_windows(train.derived_data, window_size=ws_x)\n",
    "test_ws_x, test_windows_per_serie_x =\\\n",
    "    test.split_into_windows(test.derived_data, window_size=ws_x)\n",
    "\n",
    "# Estudiamos eventos locales (series rápidas)\n",
    "ws_y = int(train.get_shortest_serie().shape[0]/2)\n",
    "train_ws_y, train_windows_per_serie_y =\\\n",
    "    train.split_into_windows(train.derived_data, window_size=ws_y)\n",
    "test_ws_y, test_windows_per_serie_y =\\\n",
    "    test.split_into_windows(test.derived_data, window_size=ws_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_extraction import Data\n",
    "\n",
    "train_large_windows = Data(train_ws_x, train_windows_per_serie_x)\n",
    "test_large_windows = Data(test_ws_x, test_windows_per_serie_x)\n",
    "\n",
    "train_short_windows = Data(train_ws_y, train_windows_per_serie_y)\n",
    "test_short_windows = Data(test_ws_y, test_windows_per_serie_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Codificación sobre las ventanas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.codifications import temporal_trend_fn\n",
    "\n",
    "train_large_windows.apply_codifications([temporal_trend_fn])\n",
    "test_large_windows.apply_codifications([temporal_trend_fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Diseño de la topología del bosque </font>\n",
    "- Número de árboles inicial recomendado\n",
    "- Número de símbolos inicial recomendado\n",
    "- Número de árboles del segundo RandomForest recomendado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Visualización de resultados preliminares </font>\n",
    "- Visualización de sobreajuste\n",
    "  - Para mitigarlo hay que disminuir el número de árboles del segundo RF (es el que clasifica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Randomized Search </font>\n",
    "- Búsqueda de hiper-parámetros aleatoria con SMTS maximizando ``macro avg f1-score``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import utils.constants as cs\n",
    "from smts_implementation.smts import SMTS\n",
    "from utils.classifier_utils import (windowed_cross_val,\n",
    "                                    compute_classification_reports_means)\n",
    "from utils.plot_utils import pretty_print_classification_report_dict\n",
    "\n",
    "PKL_DIR = 'pkl/SMTS/'\n",
    "\n",
    "\n",
    "def smts_randomized_search_cv(\n",
    "        windowed_series,\n",
    "        relation_with_series,\n",
    "        prefix,\n",
    "        cv=5):\n",
    "    global PKL_DIR\n",
    "    all_clf_used = {}\n",
    "\n",
    "    n_samples = 5\n",
    "    j_ins_list = random.sample([20, 50, 100, 150, 200], n_samples)\n",
    "    n_symbols_list = random.sample([20, 50, 100, 150, 200], n_samples)\n",
    "\n",
    "    best_hyp_params = None\n",
    "    best_score = 0\n",
    "    for j_ins in j_ins_list:\n",
    "        for n_symbols in n_symbols_list:\n",
    "            clf_used = {}\n",
    "            clf = SMTS(\n",
    "                j_ins=j_ins,\n",
    "                n_symbols=n_symbols,\n",
    "                random_state=SEED\n",
    "            )\n",
    "\n",
    "            reports = windowed_cross_val(\n",
    "                clf,\n",
    "                windowed_series,\n",
    "                relation_with_series,\n",
    "                estimator_type=cs.ESTIMATOR_SMTS,\n",
    "                cv=cv,\n",
    "                drop_columns=['class'],\n",
    "                seed=SEED\n",
    "            )\n",
    "            mean_report = compute_classification_reports_means(reports)\n",
    "            all_clf_used[(j_ins, n_symbols)] = (clf_used, str(mean_report))\n",
    "\n",
    "            if mean_report['macro avg']['f1-score'] >= best_score:\n",
    "                best_score = mean_report['macro avg']['f1-score']\n",
    "                best_hyp_params = (j_ins, n_symbols)\n",
    "                best_report = mean_report\n",
    "\n",
    "            print(\"\\t\\t--------------ACTUAL BEST: J_ins={}; N_symbols={}--------------\"\n",
    "                  .format(best_hyp_params[0], best_hyp_params[1]))\n",
    "            pretty_print_classification_report_dict(best_report)\n",
    "            print(\"\\t\\t--------------ITERATION: J_ins={}; N_symbols={}--------------\"\n",
    "                  .format(j_ins, n_symbols))\n",
    "            pretty_print_classification_report_dict(mean_report)\n",
    "\n",
    "    with open(PKL_DIR + prefix, 'wb') as file:\n",
    "        pickle.dump(all_clf_used, file)\n",
    "\n",
    "    return best_hyp_params, best_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smts_randomized_search_cv(\n",
    "    train_large_windows.derived_data,\n",
    "    train_large_windows.derived_data_windows_per_serie,\n",
    "    \"smts_sample\",\n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Randomized Search con múltiples ejecuciones en lugar de Validación Cruzada </font>\n",
    "- Solo si tenemos pocos datos\n",
    "- Ejecutaremos el mismo modelo sobre diferentes particiones del conjunto de datos original para observar su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Análisis de resultados </font>\n",
    "- TODO - Un breve análisis de los resultados obtenidos para las diferentes resoluciones, ventanas, ...\n",
    "- Visualización de gráficos para determinar si se pueden obtener mejores resultados con una serie de hiper-parámetros concretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Conclusiones </font>\n",
    "- TODO - Unas breves conclusiones sobre los resultados obtenidos (influencia de la codificación, ...)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a096ff48e453ebcfb843df4ab333716150f391fd6f6f069a95d41746473af77b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tfg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
