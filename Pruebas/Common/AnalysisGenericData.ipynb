{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Propósito principal </font>\n",
    "- La idea de este librillo es estudiar la composición y la forma de los datos de un conjunto de datos cualquiera.\n",
    "\n",
    "## <font color=#cd0000> Leyenda </font>\n",
    "- Los apartados titulados con el código de colores HEX: `#cd0000` serán apartados que tendrán todos los librillos, en concreto, aquellos especificados en el apartado `Síntesis de los criterios usados` del trabajo.\n",
    "- Los apartados titulados con el código de colores HEX: `#2451ff` serán apartados de conclusiones propias de este librillo resultado de aplicar un estudio personalizado para cada planteamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Prerrequisitos </font>\n",
    "## <font color=#cd0000> Entorno de ejecución </font>\n",
    "- Cambiamos el directorio raíz del librillo para acceder cómodamente a las funciones de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../../')\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Constantes y variables predefinidas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEARTBEAT_PATH = \"data/heartbeat\"\n",
    "EPILEPSY_PATH = \"data/epilepsy\"\n",
    "SEGUIMIENTO_OCULAR_PATH = \"data/seguimiento-ocular/Data/Hospital\"\n",
    "SEGUIMIENTO_OCULAR_FOLDERS_ID = range(1, 12+1)\n",
    "\n",
    "SEED = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Análisis del Dataset \\<ds\\> </font>\n",
    "- Fuente: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Extracción de datos </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Change with known data\n",
    "from utils.load_data import import_epilepsy_dataset\n",
    "\n",
    "# train, test = import_heartbeat_dataset(HEARTBEAT_PATH)\n",
    "# all_data = import_seguimiento_ocular_dataset(SEGUIMIENTO_OCULAR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(train, open(DATA_TO_SAVE + \"_tmp_train_data.pkl\", 'wb'))\n",
    "# pickle.dump(test, open(DATA_TO_SAVE + \"_tmp_test_data.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# train = pickle.load(open(DATA_TO_SAVE + \"_tmp_train_data.pkl\", 'rb'))\n",
    "# test = pickle.load(open(DATA_TO_SAVE + \"_tmp_test_data.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_changes()\n",
    "test.reset_changes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Generación automática de reporte estadístico </font>\n",
    "- Recomendación de ejecución: TODO\n",
    "- Puedes observar el reporte generado en el directorio raíz del proyecto con un navegador tras ejecutar esta celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling\n",
    "\n",
    "# report = pandas_profiling.ProfileReport(train.original_data)\n",
    "# report.to_file(output_file=\"heartbeat_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Análisis a simple vista </font>\n",
    "- Analizaremos los datos generados por el reporte automático de estadísticas brindado por Pandas-Profiling.\n",
    "\n",
    "### <font color=#cd0000> Concentración de los datos </font>\n",
    "- TODO\n",
    "\n",
    "### <font color=#cd0000> Missing Values </font>\n",
    "- TODO.\n",
    "\n",
    "### <font color=#cd0000> Matriz de correlación </font>\n",
    "- Estudiando la matriz de correlación generada a partir del coeficiente de correlación de Pearson observamos que:\n",
    "  - TODO\n",
    "\n",
    "### <font color=#cd0000> Balanceo de las clases </font>\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Análisis en profundidad </font>\n",
    "- Analizaremos las series de cada atributo en mayor profundidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Disminución de la dimensionalidad </font>\n",
    "- TODO - Mencionar si se recomienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = train.get_derived_data_columns()['attrs']\n",
    "# column_to_study = ['signal_1', 'signal_10', 'signal_20',\n",
    "#                    'signal_30', 'signal_40', 'signal_50', 'signal_60']\n",
    "\n",
    "# for col in columns_to_remove:\n",
    "#     if col in column_to_study:\n",
    "#         columns_to_remove.remove(col)\n",
    "\n",
    "# train.drop_derived_data_columns(columns_to_remove)\n",
    "# test.drop_derived_data_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#2451ff> Generación automática de reporte estadístico con reducción de la dimensionalidad </font>\n",
    "- TODO: Adjuntar enlace al reporte generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling\n",
    "\n",
    "# report = pandas_profiling.ProfileReport(train.derived_data)\n",
    "# report.to_file(output_file=\"heartbeat_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Desplazamiento entre los atributos </font>\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.plot_utils import plot_series\n",
    "# import pandas as pd\n",
    "\n",
    "# def plot_all_signals_from_serie_id(df, id):\n",
    "#     serie_id = id\n",
    "\n",
    "#     signal_1_serie = df[df['id'] == serie_id]['signal_1']\n",
    "#     signal_10_serie = df[df['id'] == serie_id]['signal_10']\n",
    "#     signal_20_serie = df[df['id'] == serie_id]['signal_20']\n",
    "#     signal_30_serie = df[df['id'] == serie_id]['signal_30']\n",
    "#     signal_40_serie = df[df['id'] == serie_id]['signal_40']\n",
    "#     signal_50_serie = df[df['id'] == serie_id]['signal_50']\n",
    "#     signal_60_serie = df[df['id'] == serie_id]['signal_60']\n",
    "\n",
    "#     series_to_plot = [signal_1_serie, signal_10_serie, signal_20_serie,\n",
    "#                     signal_30_serie, signal_40_serie, signal_50_serie,\n",
    "#                     signal_60_serie]\n",
    "\n",
    "#     labels = [\"signal_1_serie\",\n",
    "#             \"signal_10_serie\",\n",
    "#             \"signal_20_serie\",\n",
    "#             \"signal_30_serie\",\n",
    "#             \"signal_40_serie\",\n",
    "#             \"signal_50_serie\",\n",
    "#             \"signal_60_serie\"]\n",
    "\n",
    "#     plot_series(series_to_plot, labels)\n",
    "\n",
    "# identificators = pd.unique(train.derived_data['id'])\n",
    "\n",
    "# for identificator in identificators[-5:]:\n",
    "#         plot_all_signals_from_serie_id(train.derived_data, identificator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Variabilidad y velocidad de cambios </font>\n",
    "- TODO: Velocidad de cambios (series lentas o rápidas) por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# abnormal_identificators = pd.unique(\n",
    "#     train.original_data[train.original_data['class'] == 'abnormal']['id'])\n",
    "\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_1\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_10\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_20\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_30\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_40\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_50\")\n",
    "# train.plot_series_by_id(abnormal_identificators[0:5], \"signal_60\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Estacionariedad de las series </font>\n",
    "- TODO: Periodicidad de las series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Tendencia de las series </font>\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=#cd0000> Normalización de los datos </font>\n",
    "- TODO: mencionar si existe pérdida de información significativa tras normalizar DS con tendencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.codifications import standardize_data\n",
    "# from utils.plot_utils import plot_series_from_df_by_id\n",
    "\n",
    "# columns = train.get_derived_data_columns()['attrs']\n",
    "# standardized_data = standardize_data(train.original_data, headers=columns)\n",
    "\n",
    "# identificators = pd.unique(standardized_data['id'])\n",
    "\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_1\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_10\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_20\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_30\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_40\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_50\")\n",
    "# plot_series_from_df_by_id(standardized_data, identificators[0:5], \"signal_60\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Aplicación preliminar de las nociones anteriores </font>\n",
    "- TODO: Probar sobre diferentes clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.codifications import temporal_trend_fn\n",
    "\n",
    "train.apply_codifications([temporal_trend_fn])\n",
    "test.apply_codifications([temporal_trend_fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Sobre SMTS </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smts_implementation.smts import SMTS\n",
    "\n",
    "clf = SMTS(j_ins=100, n_symbols=150, random_state=2)\n",
    "clf.fit(train.derived_data.drop(['TimeStamp', 'class'], axis=1),\n",
    "        train.derived_data['class'])\n",
    "clf.score(test.derived_data.drop(['TimeStamp', 'class'], axis=1),\n",
    "          test.derived_data['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(test.derived_data.drop(['TimeStamp', 'class'], axis=1))\n",
    "y_real = test.derived_data.groupby('id').first()['class'].to_numpy()\n",
    "\n",
    "print(confusion_matrix(y_real, y_pred))\n",
    "print(classification_report(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Sobre RF </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=100, n_estimators=150)\n",
    "clf.fit(train.derived_data.drop(['id', 'class'], axis=1),\n",
    "        train.derived_data['class'])\n",
    "clf.score(test.derived_data.drop(['id', 'class'], axis=1),\n",
    "          test.derived_data['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(test.derived_data.drop(['id', 'class'], axis=1))\n",
    "y_real = test.derived_data['class'].to_numpy()\n",
    "\n",
    "print(confusion_matrix(y_real, y_pred))\n",
    "print(classification_report(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Sobre LSTM </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Preparación de los datos </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.codifications import standardize_data\n",
    "\n",
    "train.derived_data, test.derived_data = standardize_data(\n",
    "    train.derived_data,\n",
    "    test.derived_data,\n",
    "    headers=train.get_derived_data_columns()['attrs']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All lengths must be equal\n",
    "series_length = train.get_shortest_serie().shape[0]\n",
    "n_dims = len(train.get_derived_data_columns()['attrs'])\n",
    "\n",
    "(\n",
    "    train.get_shortest_serie().shape[0],\n",
    "    train.get_largest_serie().shape[0],\n",
    "    test.get_shortest_serie().shape[0],\n",
    "    test.get_largest_serie().shape[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This will determine the number of series of each split\n",
    "train_n_series = pd.unique(train.derived_data['id']).shape[0]\n",
    "test_n_series = pd.unique(test.derived_data['id']).shape[0]\n",
    "\n",
    "(train_n_series, test_n_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = train.transform_derived_data_into_X_y()\n",
    "X_test, _ = test.transform_derived_data_into_X_y()\n",
    "\n",
    "y_train = train.derived_data.groupby('id').first()['class'].to_numpy()\n",
    "y_test = test.derived_data.groupby('id').first()['class'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classifier_utils import apply_lstm_format\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y_train)\n",
    "\n",
    "X_train, y_train = apply_lstm_format(\n",
    "    X_train, y_train, train_n_series, series_length, 2, enc)\n",
    "X_test, y_test = apply_lstm_format(\n",
    "    X_test, y_test, test_n_series, series_length, 2, enc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Diseño del modelo </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "# Number of initial dimensions\n",
    "nn.add(LSTM(units=24, dropout=.2, recurrent_dropout=.2))\n",
    "# Number of Epilepsy's classes\n",
    "nn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Compilación del modelo </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "metrics = [\n",
    "    k.metrics.CategoricalAccuracy(name=\"ACC\"),\n",
    "    k.metrics.Precision(name='Prec'),\n",
    "    k.metrics.Recall(name='Rec'),\n",
    "    k.metrics.AUC(name='AUC')\n",
    "]\n",
    "nn.compile(optimizer=RMSprop(learning_rate=1e-5), \n",
    "           loss='binary_crossentropy', metrics=metrics)\n",
    "nn.build(input_shape=X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Visualización de métricas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_metrics(history):\n",
    "    for metric in history.history.keys():\n",
    "        if not metric.startswith('val_'):\n",
    "            plt.plot(history.history[metric], label=metric)\n",
    "            plt.plot(history.history[f'val_{metric}'], label=f'val_{metric}')\n",
    "            plt.title(metric)\n",
    "            plt.ylabel('')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc=\"upper left\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Entrenamiento </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "history = nn.fit(X_train, y_train, epochs=epochs,\n",
    "                 validation_data=(X_test, y_test))\n",
    "nn.summary()\n",
    "print('\\n\\n')\n",
    "\n",
    "y_pred = nn.predict(X_test)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "show_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = y_test\n",
    "print(confusion_matrix(y_real, y_pred))\n",
    "print(classification_report(y_real, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a096ff48e453ebcfb843df4ab333716150f391fd6f6f069a95d41746473af77b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tfg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
