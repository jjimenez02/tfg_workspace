{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Propósito principal </font>\n",
    "- La idea de este librillo es preparar el entorno para realizar pruebas para cualquier DataSet a ser clasificado por cualquier codificación aplicada a RF\n",
    "\n",
    "## <font color=#cd0000> Leyenda </font>\n",
    "- Los apartados titulados con el código de colores HEX: `#cd0000` serán apartados que tendrán todos los librillos, en concreto, aquellos especificados en el apartado `Síntesis de los criterios usados` del trabajo.\n",
    "- Los apartados titulados con el código de colores HEX: `#2451ff` serán apartados de conclusiones propias de este librillo resultado de aplicar un estudio personalizado para cada planteamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Prerrequisitos </font>\n",
    "## <font color=#cd0000> Entorno de ejecución </font>\n",
    "- Cambiamos el directorio raíz del librillo para acceder cómodamente a las funciones de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../..')\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Constantes y variables predefinidas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEARTBEAT_PATH = \"data/heartbeat\"\n",
    "EPILEPSY_PATH = \"data/epilepsy\"\n",
    "SEGUIMIENTO_OCULAR_PATH = \"data/seguimiento-ocular/Data/Hospital\"\n",
    "SEGUIMIENTO_OCULAR_FOLDERS_ID = range(1, 12+1)\n",
    "\n",
    "DATA_TO_SAVE = \"HeartBeat\"\n",
    "\n",
    "PKL_DIR = \"pkl/<classifier>/<ds>/\"\n",
    "PKL_NAME = \"<ds>_<classifier>_<codif>.pkl\"\n",
    "\n",
    "SEED = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Carga del Dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Change with known data\n",
    "from utils.load_data import import_epilepsy_dataset\n",
    "\n",
    "# train, test = import_heartbeat_dataset(HEARTBEAT_PATH)\n",
    "# all_data = import_seguimiento_ocular_dataset(SEGUIMIENTO_OCULAR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(train, open(DATA_TO_SAVE + \"_tmp_train_data.pkl\", 'wb'))\n",
    "# pickle.dump(test, open(DATA_TO_SAVE + \"_tmp_test_data.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# train = pickle.load(open(DATA_TO_SAVE + \"_tmp_train_data.pkl\", 'rb'))\n",
    "# test = pickle.load(open(DATA_TO_SAVE + \"_tmp_test_data.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_changes()\n",
    "test.reset_changes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Particionado inicial de los datos si fuera necesario </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.data_extraction import Data\n",
    "\n",
    "# X_train_Data, X_test_Data, y_train, y_test = all_data.train_test_split(\n",
    "#     criterion='windowed',\n",
    "#     train_size=.8,\n",
    "#     random_state=SEED,\n",
    "#     drop_columns=[]\n",
    "# )\n",
    "\n",
    "# X_train_Data = Data(X_train_Data)\n",
    "# X_test_Data = Data(X_test_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Preprocesamiento </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Eliminación de datos inválidos y valores atípicos </font>\n",
    "- TODO: Breve descripción de qué es un dato inválido (-1's en columna, etc.)\n",
    "- Eliminaremos aquellos valores fuera de los percentiles 5 y 95.\n",
    "- TODO: Definiremos cuál será el límite de outliers permitido por serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Remove invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.remove_outliers(\n",
    "    headers=train.get_derived_data_columns()['attrs'],\n",
    "    outliers_limit=.3\n",
    ")\n",
    "\n",
    "test.remove_outliers(\n",
    "    headers=test.get_derived_data_columns()['attrs'],\n",
    "    outliers_limit=.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Remaining series\n",
    "print(\"Train: Previous number of series: {}\".format(\n",
    "    len(pd.unique(train.original_data['id']))))\n",
    "print(\"Train: Actual number of series: {}\".format(\n",
    "    len(pd.unique(train.derived_data['id']))))\n",
    "\n",
    "print(\"Test: Previous number of series: {}\".format(\n",
    "    len(pd.unique(test.original_data['id']))))\n",
    "print(\"Test: Actual number of series: {}\".format(\n",
    "    len(pd.unique(test.derived_data['id']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Resoluciones a aplicar </font>\n",
    "- TODO:\n",
    "  - Si las series son rápidas (muchos cambios en poco tiempo) especificar resoluciones altas (sin modificaciones).\n",
    "  - Si las series son lentas (pocos cambios en mucho tiempo) especificar resoluciones bajas (eliminamos datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series lentas\n",
    "train.reduce_sampling_rate(remove_one_each_n_samples=2)\n",
    "test.reduce_sampling_rate(remove_one_each_n_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> División en ventanas </font>\n",
    "- Solo aplicaremos enventanado si no ha sido aplicado anteriormente\n",
    "- TODO: Especificar tamaño de ventana esperado como mejor y adjuntar otro tamaño de ventana para comparar (al menos 2 más)\n",
    "- TODO: No es necesario aplicar siempre el enventanado, revisar análisis en profundidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudiamos eventos globales (series lentas)\n",
    "ws_x = train.get_shortest_serie().shape[0]\n",
    "train_ws_x, train_windows_per_serie_x = \\\n",
    "    train.split_into_windows(train.derived_data, window_size=ws_x)\n",
    "test_ws_x, test_windows_per_serie_x = \\\n",
    "    test.split_into_windows(test.derived_data, window_size=ws_x)\n",
    "\n",
    "# Estudiamos eventos locales (series rápidas)\n",
    "ws_y = int(train.get_shortest_serie().shape[0]/2)\n",
    "train_ws_y, train_windows_per_serie_y =\\\n",
    "    train.split_into_windows(train.derived_data, window_size=ws_y)\n",
    "test_ws_y, test_windows_per_serie_y =\\\n",
    "    test.split_into_windows(test.derived_data, window_size=ws_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_extraction import Data\n",
    "\n",
    "train_large_windows = Data(train_ws_x, train_windows_per_serie_x)\n",
    "test_large_windows = Data(test_ws_x, test_windows_per_serie_x)\n",
    "\n",
    "train_short_windows = Data(train_ws_y, train_windows_per_serie_y)\n",
    "test_short_windows = Data(test_ws_y, test_windows_per_serie_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Codificación </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.codifications import temporal_trend_fn\n",
    "\n",
    "train_large_windows.apply_codifications([temporal_trend_fn])\n",
    "test_large_windows.apply_codifications([temporal_trend_fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Preparación de los datos </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.derived_data.drop(['id', 'class'], axis=1)\n",
    "X_test = test.derived_data.drop(['id', 'class'], axis=1)\n",
    "\n",
    "y_train = train.derived_data['class'].to_numpy()\n",
    "y_test = test.derived_data['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Técnicas de balanceo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Asignación de pesos a las clases </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {'abnormal': class_weights[0], 'normal': class_weights[1]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Diseño de la topología del bosque </font>\n",
    "- Número de estimadores inicial recomendado\n",
    "- Profundidad máxima recomendada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Entrenamiento </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Clasificación </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_true = np.asarray(y_test)\n",
    "    \n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Discusión de los resultados </font>\n",
    "- Vamos a estudiar diferentes rangos de hiper-parámetros interesantes que podrían darnos alguna pista sobre el rango en el que buscar el mejor clasificador de este tipo:\n",
    "  - Para un `n_estimators` pequeño (10) y una `max_depth` pequeño (10) observamos resultados muy malos en lo que a la capacidad de generalización del clasificador se refiere (clasifica muy bien, únicamente, ejemplos de la clase `abnormal`):\n",
    "    ```\n",
    "    Confusion matrix:\n",
    "    [[55337  2435]\n",
    "     [20110  2514]]\n",
    "\n",
    "    Classification report:\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "        abnormal       0.73      0.96      0.83     57772\n",
    "          normal       0.51      0.11      0.18     22624\n",
    "\n",
    "        accuracy                           0.72     80396\n",
    "       macro avg       0.62      0.53      0.51     80396\n",
    "    weighted avg       0.67      0.72      0.65     80396\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Conclusiones </font>\n",
    "- Como podemos observar ...\n",
    "- No obstante si no tuviéramos más remedio que utilizarlo de esta forma buscaríamos el mejor en el rango orientativo:\n",
    "  - `n_estimators`: [...]\n",
    "  - `max_depth`: [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Randomized Search </font>\n",
    "- Búsqueda de hiper-parámetros aleatoria con RF maximizando ``macro avg f1-score``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Rangos de búsqueda </font>\n",
    "- Como vimos anteriormente los rangos de búsqueda aleatoria de los mejores hiper-parámetros serán los siguientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS_RANGE = TODO\n",
    "MAX_DEPTH_RANGE = TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import utils.constants as cs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils.classifier_utils import (windowed_cross_val,\n",
    "                                    compute_classification_reports_means)\n",
    "from utils.plot_utils import pretty_print_classification_report_dict\n",
    "\n",
    "\n",
    "def rf_randomized_search_cv(\n",
    "        windowed_series,\n",
    "        relation_with_series,\n",
    "        prefix,\n",
    "        class_weights,\n",
    "        cv=5):\n",
    "    global PKL_DIR\n",
    "    all_clf_used = {}\n",
    "\n",
    "    n_samples = 5\n",
    "    n_estimators_list = random.sample(list(N_ESTIMATORS_RANGE), n_samples)\n",
    "    max_depth_list = random.sample(list(MAX_DEPTH_RANGE), n_samples)\n",
    "\n",
    "    best_hyp_params = None\n",
    "    best_score = 0\n",
    "    for n_estimators in n_estimators_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            clf = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=SEED,\n",
    "                class_weight=class_weights\n",
    "            )\n",
    "\n",
    "            reports = windowed_cross_val(\n",
    "                clf,\n",
    "                windowed_series,\n",
    "                relation_with_series,\n",
    "                estimator_type=cs.ESTIMATOR_SKLEARN,\n",
    "                cv=cv,\n",
    "                drop_columns=['id', 'class'],\n",
    "                seed=SEED\n",
    "            )\n",
    "            mean_report = compute_classification_reports_means(reports)\n",
    "            all_clf_used[(n_estimators, max_depth)] = mean_report\n",
    "\n",
    "            if mean_report['macro avg']['f1-score'][0] >= best_score:\n",
    "                best_score = mean_report['macro avg']['f1-score'][0]\n",
    "                best_hyp_params = (n_estimators, max_depth)\n",
    "                best_report = mean_report\n",
    "\n",
    "            print(\"\\t\\t--------------ACTUAL BEST: N_Estimators={}; Max_Depth={}--------------\"\n",
    "                  .format(best_hyp_params[0], best_hyp_params[1]))\n",
    "            pretty_print_classification_report_dict(best_report)\n",
    "            print(\"\\t\\t--------------ITERATION: N_Estimators={}; Max_Depth={}--------------\"\n",
    "                  .format(n_estimators, max_depth))\n",
    "            pretty_print_classification_report_dict(mean_report)\n",
    "\n",
    "    with open(PKL_DIR + prefix, 'wb') as file:\n",
    "        pickle.dump(all_clf_used, file)\n",
    "\n",
    "    return best_hyp_params, best_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomized_search_cv(\n",
    "    train.derived_data,\n",
    "    train.derived_data_windows_per_serie,\n",
    "    PKL_NAME,\n",
    "    class_weights,\n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Randomized Search con múltiples ejecuciones en lugar de Validación Cruzada </font>\n",
    "- Solo si tenemos pocos datos\n",
    "- Ejecutaremos el mismo modelo sobre diferentes particiones del conjunto de datos original para observar su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Análisis de resultados </font>\n",
    "- Según la búsqueda aleatoria de hiper-parámetros, la mejor combinación, es la de ``n_estimators`` = TODO y ``max_depth`` = TODO:\n",
    "    ```\n",
    "        TODO\n",
    "    ```\n",
    "- Ahora vamos a visualizar la evolución de los resultados (25 resultados) para observar cómo avanza nuestra métrica objetivo -> Macro Average F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_reports = pickle.load(open(PKL_DIR + PKL_NAME, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_score\n",
    "\n",
    "macro_avg_f1_scores = dict(map(\n",
    "    lambda z: (z, {'score': all_reports[z]['macro avg']['f1-score'][0],\n",
    "                   'std': all_reports[z]['macro avg']['f1-score'][1]}),\n",
    "    all_reports\n",
    "))\n",
    "\n",
    "plot_score(\n",
    "    [macro_avg_f1_scores],\n",
    "    ('n_estimators', 'max_depth'),\n",
    "    'RandomForest',\n",
    "    inverse=False,\n",
    "    mode='score',\n",
    "    in_same_graphic=True,\n",
    "    accuracy_mode='accuracy',\n",
    "    metric_name='Macro Average F1-Score'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_recall_scores = dict(map(\n",
    "    lambda z: (z, {'score': all_reports[z]['abnormal']['recall'][0],\n",
    "                   'std': all_reports[z]['abnormal']['recall'][1]}),\n",
    "    all_reports\n",
    "))\n",
    "\n",
    "normal_recall_scores = dict(map(\n",
    "    lambda z: (z, {'score': all_reports[z]['normal']['recall'][0],\n",
    "                   'std': all_reports[z]['normal']['recall'][1]}),\n",
    "    all_reports\n",
    "))\n",
    "\n",
    "plot_score(\n",
    "    [abnormal_recall_scores],\n",
    "    ('n_estimators', 'max_depth'),\n",
    "    'RandomForest',\n",
    "    inverse=False,\n",
    "    mode='score',\n",
    "    in_same_graphic=True,\n",
    "    accuracy_mode='accuracy',\n",
    "    metric_name='Abnormal recall score'\n",
    ")\n",
    "\n",
    "plot_score(\n",
    "    [normal_recall_scores],\n",
    "    ('n_estimators', 'max_depth'),\n",
    "    'RandomForest',\n",
    "    inverse=False,\n",
    "    mode='score',\n",
    "    in_same_graphic=True,\n",
    "    accuracy_mode='accuracy',\n",
    "    metric_name='Normal recall score'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#cd0000> Evaluación sobre el conjunto de validación </font>\n",
    "- Vamos a llevar a cabo la evaluación final sobre el conjunto de validación (esto es lo que irá al apartado de ``Pruebas y Resultados`` de la memoria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Entrenamiento </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=TODO,\n",
    "    max_depth=TODO,\n",
    "    class_weight=class_weights,\n",
    "    random_state=SEED\n",
    ")\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#cd0000> Clasificación </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_true = np.asarray(y_test)\n",
    "    \n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#cd0000> Conclusiones </font>\n",
    "- TODO - Unas breves conclusiones sobre los resultados obtenidos (influencia de la codificación, ...)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a096ff48e453ebcfb843df4ab333716150f391fd6f6f069a95d41746473af77b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tfg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
